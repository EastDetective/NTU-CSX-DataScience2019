{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Facebook Career Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* selenium\n",
    "* one of the following (depending on which browser you're using)\n",
    "  * firefox: [geckodriver](https://github.com/mozilla/geckodriver/releases/)\n",
    "  * chrome/chromium: [chromedriver](http://chromedriver.chromium.org/)\n",
    "  \n",
    "## Useful Tutorials\n",
    "* https://huilansame.github.io/huilansame.github.io/archivers/sleep-implicitlywait-wait\n",
    "* https://wangxin1248.github.io/python/2018/09/python3-spider-8.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scraping a single page into a GoogleJob object\n",
    "Use `scrape_job()` provided below on single job with its url.\n",
    "\n",
    "Example target: https://careers.google.com/jobs/results/6163626811654144-front-end-software-engineer/?company=Google&company=YouTube&employment_type=FULL_TIME&hl=en_US&jlo=en_US&q=software&sort_by=relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import selenium.webdriver.support.ui as ui\n",
    "\n",
    "import pandas\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_job(url: str, wait: WebDriverWait, retry=3):\n",
    "    \"\"\" Scrape the job info from the specified Url. A broswer driver MUST be initialized beforehand.\n",
    "    :param url: the url of a detailed google job page.\n",
    "    :param wait: contains timeout.\n",
    "    :param retry: times to retry.\n",
    "    :return: a dict wrapping all info.\n",
    "    \"\"\"\n",
    "    for i in range(0, retry):\n",
    "        driver.get(url)\n",
    "    \n",
    "        # Wait until all required elements are generated.\n",
    "        try:\n",
    "            wait.until(ec.presence_of_element_located((By.CLASS_NAME, '_1kdc')))\n",
    "            wait.until(ec.presence_of_element_located((By.CLASS_NAME, '_3-8r')))\n",
    "            \n",
    "            # Extract job information.\n",
    "            title = driver.find_element_by_class_name('_1kdc').text\n",
    "            location = driver.find_element_by_class_name('_3-8r').text\n",
    "            contents = driver.find_elements_by_class_name('_3-8q')[1:]\n",
    "            responsibilities = contents[0].find_element_by_class_name('_6ad2').text\n",
    "            minimum_qual = contents[1].find_element_by_class_name('_6ad2').text\n",
    "            preferred_qual = contents[2].find_element_by_class_name('_6ad2').text\n",
    "            \n",
    "            return {\n",
    "                'title': title,\n",
    "                'loc': location,\n",
    "                'minimum_qual': minimum_qual,\n",
    "                'preferred_qual': preferred_qual,\n",
    "                'resp': responsibilities\n",
    "            }\n",
    "        except TimeoutException:\n",
    "            return None\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    # If all retries have failed, return None.\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Software Engineer, Database Engineering', 'loc': 'Menlo Park, CA', 'minimum_qual': '5+ years software engineering experience or coding experience in C, C++, or Java\\n2+ years experience building database software\\nB.S. Computer Science or related technical field', 'preferred_qual': 'Experience working directly with database systems at scale\\nM.S. or PhD in Computer Science or related technical field', 'resp': 'Design core software components for database systems\\nCode using primarily in C++\\nInterface with other teams to collaborate in transforming the landscape\\nConduct design and code reviews\\nAnalyze and improve efficiency, scalability, and stability of various system resources'}\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.add_argument('-headless')\n",
    "driver = Firefox(executable_path='/opt/firefox/geckodriver', options=options)\n",
    "\n",
    "wait = WebDriverWait(driver, timeout=10)\n",
    "job = scrape_job(r'https://www.facebook.com/careers/jobs/823133274532759/', wait)\n",
    "\n",
    "if job is not None:\n",
    "    print(job)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search & Scrape All Relevant Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `scrape_jobs(keyword, wait)` provided below on all jobs relevant to a specific keyword.\n",
    "\n",
    "Example: all jobs related to the keyword `software`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collect_urls(wait: WebDriverWait, urls: list, page_count, url_count):\n",
    "    \"\"\" Collect all urls we have to scrape \"\"\"\n",
    "    for i in range(0, page_count):\n",
    "        try:\n",
    "            time.sleep(2) # Sleep for 2 secs for the page to load or it will scream like a bitch\n",
    "            \n",
    "            wait.until(ec.presence_of_element_located((By.CLASS_NAME, '_2ynk')))\n",
    "            result_pane = driver.find_element_by_class_name('_2ynk')\n",
    "            cards = result_pane.find_elements_by_class_name('_69jm')\n",
    "            driver.get(cards[0].get_attribute('href'))\n",
    "            \n",
    "            urls += [card.get_attribute('href') for card in cards]\n",
    "            print('\\rCollecting urls... {}/{}'.format(len(urls), url_count), end='')\n",
    "            \n",
    "            # If `next` cannot be found after `timeout` seconds, it will throw \n",
    "            # a TimeoutException, then we can break the loop.\n",
    "            wait.until(ec.presence_of_element_located((By.ID, 'u_6_9')))\n",
    "            driver.find_element_by_id('u_6_9').send_keys(Keys.RETURN)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_jobs(keyword: str, wait: WebDriverWait, urls: list, start=1):\n",
    "    \"\"\" Scrape info of all jobs related to the specified keyword\n",
    "    :param keyword: google job search keyword.\n",
    "    :param wait: contains timeout.\n",
    "    :param urls: urls cache.\n",
    "    :param start: the number of the record to start scraping.\n",
    "    \"\"\"\n",
    "    items_per_page = 10\n",
    "    starting_page = start // items_per_page + 1\n",
    "    starting_card_no = start - (starting_page - 1) * items_per_page\n",
    "    \n",
    "    # Open Google job search page.\n",
    "    driver.get(r'https://www.facebook.com/careers/jobs/?q={}&page={}'.format(keyword, starting_page));\n",
    "    \n",
    "    wait.until(ec.presence_of_element_located((By.CLASS_NAME, '_2ynk')))\n",
    "    result_pane = driver.find_element_by_class_name('_2ynk')\n",
    "    url_count = int(result_pane.find_element_by_class_name('_6ci_').text.split('(')[1].split(')')[0])\n",
    "    page_count = (url_count // items_per_page) + 1\n",
    "    \n",
    "    # Loop until there's no `next` hyperlink.\n",
    "    print('Collecting urls...', end='')\n",
    "    \n",
    "    if len(urls) != url_count:\n",
    "        urls.clear()\n",
    "        _collect_urls(wait, urls, page_count, url_count)\n",
    "    \n",
    "    with open('facebook_jobs.csv', 'w') as f:\n",
    "        w = csv.DictWriter(f, fieldnames = ['title', 'loc', 'minimum_qual', 'preferred_qual', 'resp'])\n",
    "        w.writeheader()\n",
    "        \n",
    "        for i in range(start - 1, len(urls)):\n",
    "            print('\\rProcessing ({}/{}): {}'.format(i, len(urls), urls[i]), end='')\n",
    "            job = scrape_job(urls[i], wait)\n",
    "            \n",
    "            if job is not None:\n",
    "                w.writerow(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll cache all urls we have to scrape later in this list.\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urls...Message: The element reference of <a class=\"_69jm\" href=\"/careers/jobs/168732237316966/\"> is stale; either the element is no longer attached to the DOM, it is not in the current frame context, or the document has been refreshed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.add_argument('-headless')\n",
    "driver = Firefox(executable_path='/opt/firefox/geckodriver', options=options)\n",
    "\n",
    "wait = WebDriverWait(driver, timeout=10)\n",
    "scrape_jobs('software', wait, urls, start=1)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
